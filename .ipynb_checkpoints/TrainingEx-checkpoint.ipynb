{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fullname': 'YH', 'html': '<p class=\"TweetTextSize js-tweet-text tweet-text\" data-aria-label-part=\"0\" lang=\"in\">Jumat bersepedah,yu ah menggoes bareng <a class=\"twitter-atreply pretty-link js-nav\" data-mentioned-user-id=\"80323736\" dir=\"ltr\" href=\"/ridwankamil\"><s>@</s><b><strong>ridwankamil</strong></b></a> ke @Taman_Jomblo hahahahhahah</p>', 'id': '429039792500637696', 'likes': 0, 'replies': 0, 'retweets': 0, 'text': 'Jumat bersepedah,yu ah menggoes bareng @ridwankamil ke @Taman_Jomblo hahahahhahah', 'timestamp': '2014-01-30T23:53:52', 'url': '/HermawanYana/status/429039792500637696', 'user': 'HermawanYana'}\n"
     ]
    }
   ],
   "source": [
    "import codecs, json\n",
    "with codecs.open('tweetsFix.json','r','utf-8') as f:\n",
    "    text=json.load(f, encoding='utf-8')\n",
    "    print(text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessing(text=\"\",\n",
    "                  casefolding=True,\n",
    "                  url_add=True,\n",
    "                  username=True,\n",
    "                  removeusername=True,\n",
    "                  removenonalphabet=True,\n",
    "                  removestopword=True,\n",
    "                  stemming=True,\n",
    "                  removehashtag=True,\n",
    "                  removeemail=True, \n",
    "                  removeRT=True,\n",
    "                  removeAdr=True):\n",
    "    if(text!=\"\"):\n",
    "       \n",
    "        if(casefolding):\n",
    "            text = text.lower()\n",
    "            \n",
    "        if(removeRT):\n",
    "            import re\n",
    "            rt= re.compile(r'RT\\D*\\D?\\w+\\W?\\D+')\n",
    "            text = re.sub(rt, ' ', text)\n",
    "        \n",
    "        if(removeusername):\n",
    "            nama = re.compile(\"(?:^|\\s)[＠ @]{1}([^\\s#<>[\\]|{}]+)\", re.UNICODE)\n",
    "            text = re.sub(nama, ' ', text)\n",
    "            \n",
    "        if(username):\n",
    "            user = re.compile(\"[＠ @]{1}([^\\s#<>[\\]|{}]+):\", re.UNICODE)\n",
    "            text = re.sub(user, ' ', text) \n",
    "        \n",
    "        if(removeAdr):\n",
    "            com= re.compile(r'\\w+\\.\\w+\\.*\\w*\\D\\w*')\n",
    "            text = re.sub(com, ' ', text)\n",
    "         \n",
    "        if(url_add):\n",
    "            text = re.sub('http\\S+\\s*', ' ', text)\n",
    "            \n",
    "        if(removehashtag):\n",
    "            hashtag = re.compile(\"(?:^|\\s)[＃#]{1}(\\w+)\", re.UNICODE)\n",
    "            text = re.sub(hashtag, ' ', text)\n",
    " \n",
    "        if(removeemail):\n",
    "            email = re.compile(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+')\n",
    "            text = re.sub(email, ' ', text) \n",
    "            \n",
    "        if(removenonalphabet):\n",
    "            import re\n",
    "            text = ' '.join(re.findall(r'\\b[a-z]+?[a-z]+\\b',text))\n",
    "    \n",
    "        if(removestopword):\n",
    "            from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "            factory = StopWordRemoverFactory()\n",
    "            Sastrawi_StopWords_id = factory.get_stop_words()\n",
    "            temp = [t for t in re.findall(r'\\b[a-z]+-?[a-z]+\\b',text) if t not in Sastrawi_StopWords_id]\n",
    "            text = ' '.join(temp)\n",
    "        if(stemming):\n",
    "            from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "            stemmer = StemmerFactory().create_stemmer()\n",
    "            text   = stemmer.stem(text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "filejson=open(\"tweetsFix.json\")\n",
    "data=json.loads(filejson.read())\n",
    "komentar = []\n",
    "kata=[]\n",
    "for item in data[0:419]:\n",
    "    r={}\n",
    "    r['text'] = preprocessing(item['text'])\n",
    "    komentar.append(r)\n",
    "    tweet=r['text'] if 'text' in item else item\n",
    "    \n",
    "    \n",
    "    file = open(\"kamus.txt\", encoding=\"utf-8\", errors='replace')\n",
    "    Teks = file.readlines()\n",
    "    Teks_string=' '.join(Teks)\n",
    "    fix=eval(Teks_string)\n",
    "    \n",
    "    t=\" \",tweet,\" \"\n",
    "    t_string=' '.join(t)\n",
    "    t_jadi=t_string \n",
    "    \n",
    "    for slang, formal in fix.items():\n",
    "        t_jadi = t_jadi.replace(slang,formal)\n",
    "    kata.append(t_jadi)\n",
    "\n",
    "print(len(kata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Antonim </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nlp_if_lib as nlp\n",
    "import urllib, json\n",
    "from spacy.lang.id import Indonesian\n",
    "nlp_id_spacy = Indonesian() \n",
    "\n",
    "kataJadi=[]\n",
    "lenKata=len(kata)\n",
    "for t in range(0,lenKata):\n",
    "    teksAnt=[]\n",
    "    kataStrip=kata[t].strip()\n",
    "    kataToken = nlp_id_spacy(kataStrip)  \n",
    "    token_pos = nlp.getPOSTag()\n",
    "    \n",
    "    for x in kataToken:\n",
    "        teksAnt.append(x.text)\n",
    "    \n",
    "    lenTeksAnt=len(teksAnt)   \n",
    "    for y in range(0,lenTeksAnt):\n",
    "        antonim=[]\n",
    "        if(teksAnt[y]==\"tidak\"):\n",
    "            for token in kataToken:\n",
    "                m=token.lemma_\n",
    "                try: \n",
    "                    pos=token_pos[token.lemma_]\n",
    "                    if(token_pos[teksAnt[y+1]]==\"adj\"):\n",
    "                        url = \"http://kateglo.com/api.php?format=json&phrase=\"+teksAnt[y+1]\n",
    "                        respon = urllib.request.urlopen(url)\n",
    "                        data = json.loads(respon.read())\n",
    "                        post = data[\"kateglo\"][\"all_relation\"]\n",
    "\n",
    "                        lenPost=len(post)\n",
    "                        for x in range(0,lenPost):\n",
    "                            value=post[x]\n",
    "                            if(value['rel_type']=='a'):\n",
    "                                ant=value['related_phrase']\n",
    "                                antonim.append(ant)\n",
    "                                teksAnt[y+1]=\"\"\n",
    "                                teksAnt[y]=\"\" \n",
    "                    \n",
    "                except:\n",
    "                    pos='n'\n",
    "            \n",
    "\n",
    "    \n",
    "    listAnt=len(antonim)\n",
    "    for i in range(0,listAnt):\n",
    "        teksAnt.append(antonim[i])\n",
    "        \n",
    "    ubahAnt=' '.join(teksAnt)\n",
    "    kataJadi.append(ubahAnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenKata=len(kataJadi)\n",
    "for i in range(0,lenKata):\n",
    "    for j in range(i+1,lenKata):\n",
    "        if(kataJadi[i]==kataJadi[j]):\n",
    "            kataJadi[j]=\"\"\n",
    "\n",
    "for h in kataJadi:\n",
    "    if(h==\"\"):\n",
    "        kataJadi.remove(h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Query Expansion </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Menggunakan file kata_dasar.txt\n",
    "import PyPDF2\n",
    "import urllib, json\n",
    "import nlp_if_lib as nlp\n",
    "from spacy.lang.id import Indonesian\n",
    "\n",
    "nlp_id_spacy = Indonesian() \n",
    "kataEx=[]\n",
    "\n",
    "#Teks=kataToken,tweet=kataStrip\n",
    "\n",
    "lenKata=len(kataJadi)\n",
    "for i in range(0,lenKata):\n",
    "    sinonim=[]\n",
    "    teksA=[]\n",
    "    kataStrip=kataJadi[i].strip()\n",
    "    kataToken = nlp_id_spacy(kataStrip)  \n",
    "    token_pos = nlp.getPOSTag()\n",
    "    \n",
    "    for x in kataToken:#tokenisasi tweet\n",
    "        teksA.append(x.text)\n",
    "    \n",
    "    for token in kataToken:#mengambil sinonim\n",
    "        t=token.lemma_\n",
    "        \n",
    "        try: \n",
    "            pos=token_pos[token.lemma_]\n",
    "            if(token_pos[token.lemma_]==\"adj\" or token_pos[token.lemma_]==\"adv\"):\n",
    "                kataAdj=token.lemma_\n",
    "                \n",
    "                url = \"http://kateglo.com/api.php?format=json&phrase=\"+kataAdj\n",
    "                respon = urllib.request.urlopen(url)\n",
    "                dataSyn = json.loads(respon.read())\n",
    "\n",
    "                post = dataSyn[\"kateglo\"][\"all_relation\"]\n",
    "                \n",
    "                lenPost=len(post)\n",
    "                for x in range(0,lenPost):\n",
    "                    value=post[x]\n",
    "                    if(value['rel_type']=='s'):\n",
    "                        if(value['lex_class']=='adj'):\n",
    "                            syn=value['related_phrase']\n",
    "                            sinonim.append(syn)\n",
    "\n",
    "        except:\n",
    "            pos='n'\n",
    " \n",
    "    \n",
    "    listSyn=len(sinonim)\n",
    "    for z in range(0,listSyn):\n",
    "        teksA.append(sinonim[z])\n",
    "    \n",
    "    queryEx=' '.join(teksA)\n",
    "    kataEx.append(queryEx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dt = pd.DataFrame(kataEx, columns=['text'])\n",
    "\n",
    "dt.to_csv(\"1tweetTrainEx.csv\",  encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text\n",
      "0      cimahi hayang cimbuleuit pan kota bapak naha...\n",
      "1      jumat sudah ayo ah menggoes bareng hahahahha...\n",
      "2      hayu wargi bandung tiasa sarumping mangga ra...\n",
      "3      diri taman jomblo bandung ridwan kamil agung...\n",
      "4      siapa yang jaga siapa yang pelihara kalau ru...\n",
      "5      tetot fera sudah punya sim bapak fera tidak ...\n",
      "6      beliau lahir pagerageung ti tasik bapak good...\n",
      "7      busy at sir what doa you say kababayan in en...\n",
      "8      walikota dengan program biopori saurna kbb p...\n",
      "9      bapak fera tidak punya sim tapi sudah jalan ...\n",
      "10     kelurahan sukamaju cimanggis depok urus sura...\n",
      "11        bapak kapan bandung karya bapak rindu diri  \n",
      "12     pagi bapak tinjau empat supratman anak kecil...\n",
      "13         walikota bandung lantik elih sudiapermana  \n",
      "14                                 bapak kagum bapak  \n",
      "15     bapak pagi pagi depan pasar ujungberung suka...\n",
      "16     bangga teu bapak teater anak ekonomi bandung...\n",
      "17                                      lanjut bapak  \n",
      "18     cayoo sukses orang walikota tidak bawa persi...\n",
      "19                                         cinta itu  \n",
      "20     bapak sebab celaka teh sanes jalan nu lubang...\n",
      "21     coba bapak jalan rajalwali timur pasar andir...\n",
      "22     jalan buah batu dekat tol lubang cukup bapak...\n",
      "23                                             bapak  \n",
      "24     gas terus jalan raya sudah gitu buat kereta ...\n",
      "25     malam lewat paspati sengaja ingin liat yang ...\n",
      "26     kirim proposal balaikota kalau undang bapak ...\n",
      "27     bandung smart city proyek apa saja bapak tod...\n",
      "28                     walikota bandung canang tahun  \n",
      "29     kalau hujan hari alias banjir not gong xi fa...\n",
      "..                                                 ...\n",
      "385    semakin banyak yang campaign macam begini ba...\n",
      "386    karena kalau tidak wacana begini secara blow...\n",
      "387    memang kalau liat sisi seperti pamer ibadah ...\n",
      "388    mungkin supaya pantau saja kalau tingkat sam...\n",
      "389                   kalau aku lebih pilih presiden  \n",
      "390          terima kasih bapak wali assalamualaikum  \n",
      "391    lah yang percaya allah untuk lindung dari se...\n",
      "392    rasa malu malu karena peluk agama yang palin...\n",
      "393    murak tumpeng atas berkah usia ketua kartara...\n",
      "394    karena walaupun mnyelamatkn ekor hewan tapi ...\n",
      "395    selamat ekor hewan begitu haru bahkan sentuh...\n",
      "396    tanam sifat kasih sayang yang lebih kepada u...\n",
      "397    sebagai orang islam aku karena tersebut tela...\n",
      "398    atau beri kb yang kelola nasrani yang mereka...\n",
      "399    karena sudah sangat lapar bagaimana bapak si...\n",
      "400    dengan kasus yang sama lihat beruang madu ma...\n",
      "401    sekitar tahun yang lalu lihat tidak mampu da...\n",
      "402    bapak kalau boleh usul kebun binatang bandun...\n",
      "403                                    jangan ngamuk  \n",
      "404    andai saja bapak jadi calon presiden bapak k...\n",
      "405    pimpin periksa dulu masalah jangan langsung ...\n",
      "406    kerja yang paling senang dunia hobi bayar ri...\n",
      "407                    pimpin bina organisasi ngamuk  \n",
      "408          mohon sangat depan hindar pimpin ngamuk  \n",
      "409    lebih sayang uang hutan ayo ikut mal nasinal...\n",
      "410                 pasar kosambi bandung tidak awat  \n",
      "411    enak kirim link upload lalu twitter imel bap...\n",
      "412    selamat pagi selamat jalan tugas untuk bapak...\n",
      "413    manfaat air hujan bapak harap bapak lihat be...\n",
      "414    ieu rek demo saritem dijadikeun pasar emas i...\n",
      "\n",
      "[415 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('1tweetTrainEx.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
