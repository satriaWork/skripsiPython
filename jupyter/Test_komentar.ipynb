{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test Tweet</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Input Text</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text=\"Bpk @ridwankamil43 tidak sebaik dahulu 20 ridwan43@gmail.com pic.twitter.com/DDAFssa232dsa #ridwangembel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "kumpText=[]\n",
    "def preprocessing(text=\"\",\n",
    "                  casefolding=True,\n",
    "                  removeusername=True,\n",
    "                  removenonalphabet=True,\n",
    "                  removestopword=True,\n",
    "                  stemming=True,\n",
    "                  removehashtag=True,\n",
    "                  removeemail=True,\n",
    "                  removeAdr=True):\n",
    "    \n",
    "    if(text!=\"\"):\n",
    "        import re\n",
    "       \n",
    "        if(casefolding):\n",
    "            text = text.lower()\n",
    "            print(\"Case Folding = \"+text)\n",
    "            \n",
    "        if(removeusername):\n",
    "            nama = re.compile(\"(?:^|\\s)[＠ @]{1}([^\\s#<>[\\]|{}]+)\", re.UNICODE)\n",
    "            text = re.sub(nama, ' ', text)\n",
    "            print(\"Remove Username = \"+text)\n",
    "\n",
    "        \n",
    "        if(removeAdr):\n",
    "            com= re.compile(r' \\w+\\.\\w+\\.*\\w*\\D\\w*')\n",
    "            text = re.sub(com, ' ', text)\n",
    "            print(\"Remove Address = \"+text)\n",
    "\n",
    "            \n",
    "        if(removehashtag):\n",
    "            hashtag = re.compile(\"(?:^|\\s)[＃#]{1}(\\w+)\", re.UNICODE)\n",
    "            text = re.sub(hashtag, ' ', text)\n",
    "            print(\"Remove Hashtag = \"+text)\n",
    " \n",
    "        if(removeemail):\n",
    "            email = re.compile(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+')\n",
    "            text = re.sub(email, ' ', text) \n",
    "            print(\"Remove Email = \"+text)\n",
    "            \n",
    "        if(removenonalphabet):\n",
    "            import re\n",
    "            text = ' '.join(re.findall(r'\\b[a-z]+?[a-z]+\\b',text))\n",
    "            print(\"Remove non Alphabet = \"+text)\n",
    "    \n",
    "        if(removestopword):\n",
    "            from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "            factory = StopWordRemoverFactory()\n",
    "            Sastrawi_StopWords_id = factory.get_stop_words()\n",
    "            temp = [t for t in re.findall(r'\\b[a-z]+-?[a-z]+\\b',text) if t not in Sastrawi_StopWords_id]\n",
    "            text = ' '.join(temp)\n",
    "            print(\"Remove Stopword = \"+text)\n",
    "            \n",
    "        if(stemming):\n",
    "            from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "            stemmer = StemmerFactory().create_stemmer()\n",
    "            text   = stemmer.stem(text)\n",
    "            print(\"Stemming = \"+text)\n",
    "            \n",
    "    return(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mengolah Teks dan Normalisasi Kata</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folding = bpk @ridwankamil43 tidak sebaik dahulu 20 ridwan43@gmail.com pic.twitter.com/ddafssa232dsa #ridwangembel\n",
      "Remove Username = bpk  tidak sebaik dahulu 20 ridwan43@gmail.com pic.twitter.com/ddafssa232dsa #ridwangembel\n",
      "Remove Address = bpk  tidak sebaik dahulu 20 ridwan43@gmail.com  #ridwangembel\n",
      "Remove Hashtag = bpk  tidak sebaik dahulu 20 ridwan43@gmail.com  \n",
      "Remove Email = bpk  tidak sebaik dahulu 20    \n",
      "Remove non Alphabet = bpk tidak sebaik dahulu\n",
      "Remove Stopword = bpk tidak sebaik\n",
      "Stemming = bpk tidak baik\n",
      "  bapak tidak baik  \n"
     ]
    }
   ],
   "source": [
    "bersih=preprocessing(text)\n",
    "\n",
    "file = open(\"kamus.txt\", encoding=\"utf-8\", errors='replace')\n",
    "Teks = file.readlines()\n",
    "Teks_string=' '.join(Teks)\n",
    "fix=eval(Teks_string)\n",
    "\n",
    "\n",
    "t=\" \",bersih,\" \"\n",
    "t_string=' '.join(t)\n",
    "t_jadi=t_string \n",
    "    \n",
    "for slang, formal in fix.items():\n",
    "    t_jadi = t_jadi.replace(slang,formal)\n",
    "print(t_jadi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Negasi</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bapak   buruk jahat zalim\n"
     ]
    }
   ],
   "source": [
    "import nlp_if_lib as nlp\n",
    "import urllib, json\n",
    "import requests\n",
    "from spacy.lang.id import Indonesian\n",
    "nlp_id_spacy = Indonesian() \n",
    "\n",
    "teksAnt=[]\n",
    "\n",
    "kataStrip=t_jadi.strip()\n",
    "kataToken = nlp_id_spacy(kataStrip)  \n",
    "token_pos = nlp.getPOSTag()\n",
    "    \n",
    "for x in kataToken:\n",
    "    teksAnt.append(x.text)\n",
    "    \n",
    "lenTeksAnt=len(teksAnt)   \n",
    "for y in range(0,lenTeksAnt):\n",
    "    antonim=[]\n",
    "    if(teksAnt[y]==\"tidak\" or teksAnt[y]==\"kurang\" or teksAnt[y]==\"belum\"):\n",
    "        for token in kataToken:\n",
    "            t=token.lemma_\n",
    "            try: \n",
    "                pos=token_pos[token.lemma_]\n",
    "                if(token_pos[teksAnt[y+1]]==\"adj\"):\n",
    "                    url = \"http://kateglo.com/api.php?format=json&phrase=\"+teksAnt[y+1]\n",
    "                    response = requests.get(url)\n",
    "                    data=response.text\n",
    "                    parsed=json.loads(data)\n",
    "                    post = parsed[\"kateglo\"][\"relation\"][\"a\"]\n",
    "                    lenPost=len(post)\n",
    "                    for x in range(0,lenPost):\n",
    "                        st=str(x)\n",
    "                        value=post[st]\n",
    "                        if(value['rel_type']=='a'):\n",
    "                            if(value['lex_class']=='adj'):\n",
    "                                ant=value['related_phrase']\n",
    "                                antonim.append(ant)\n",
    "                                teksAnt[y+1]=\"\"\n",
    "                                teksAnt[y]=\"\"\n",
    "\n",
    "            except:\n",
    "                pos='n'\n",
    "            \n",
    "                \n",
    "            \n",
    "    listAnt=len(antonim)\n",
    "    for i in range(0,listAnt):\n",
    "        teksAnt.append(antonim[i])\n",
    "        \n",
    "ubahAnt=' '.join(teksAnt)\n",
    "kataJadi=ubahAnt\n",
    "print(kataJadi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "oke\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "filename='MNB.model'\n",
    "\n",
    "file=open('model\\\\'+filename,'rb')\n",
    "bobot_model=pickle.load(file)\n",
    "model=pickle.load(file)\n",
    "\n",
    "print(bobot_model)\n",
    "print(model)\n",
    "\n",
    "print('oke')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pembobotan</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bapak 1.0\n"
     ]
    }
   ],
   "source": [
    "bobot=bobot_model.transform([kataJadi])\n",
    "matrix_bobot=bobot.toarray()\n",
    "x_test=matrix_bobot\n",
    "\n",
    "doc = 0\n",
    "feature_names=bobot_model.get_feature_names()\n",
    "feature_index=bobot[doc,:].nonzero()[1]\n",
    "tfidf_scores=zip(feature_index,[bobot[doc,x] for x in feature_index])\n",
    "\n",
    "for w, s in [(feature_names[i],s) for (i,s) in tfidf_scores]:\n",
    "    print(w,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prediksi</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positif :0.5200499376790843\n",
      "negatif :0.47995006232091586\n"
     ]
    }
   ],
   "source": [
    "predict=model.predict(x_test)\n",
    "prob_n, prob_p=model.predict_proba(x_test)[0]\n",
    "\n",
    "print(\"positif :\"+str(prob_p))\n",
    "print(\"negatif :\"+str(prob_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hasil</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bpk @ridwankamil43 tidak sebaik dahulu 20 ridwan43@gmail.com pic.twitter.com/DDAFssa232dsa #ridwangembel\n",
      "1\n",
      "positif\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print(predict[0])\n",
    "if(predict[0]==1):\n",
    "    print(\"positif\")\n",
    "else:\n",
    "    print(\"negatif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
